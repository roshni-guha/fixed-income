{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "860ab9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1721add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def getPricesFromCSV(file_path, reference_dates):\n",
    "    # get all the data from the csv file where the dates are in the reference_dates list\n",
    "    df = pd.read_csv(reference_dates, skiprows=15)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    date_series = df[\"Date\"]\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    # if format of date is MM/DD/YY, convert it to datetime\n",
    "    if type(df[\"Date\"].iloc[0]) == numpy.int64:\n",
    "\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y%m%d\")\n",
    "    # if format of date is YYYYMMDD, convert it to datetime\n",
    "    else:\n",
    "\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%m/%d/%y\")\n",
    "\n",
    "    df_filtered = df[df[\"Date\"].isin(date_series)]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "118f6cc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataFrame_H5A4 = \u001b[43mgetPricesFromCSV\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:/Users/nimas/Regentfund Repository/fixed-income/Data Files/H5A4.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m dataFrame_SPY = getPricesFromCSV(\u001b[33m\"\u001b[39m\u001b[33m/fixed-income/Data Files/SPY 1.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m dataFrame_G5O2 = getPricesFromCSV(\u001b[33m\"\u001b[39m\u001b[33m/fixed-income/Data Files/G5O2.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mgetPricesFromCSV\u001b[39m\u001b[34m(file_path, reference_dates)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgetPricesFromCSV\u001b[39m(file_path, reference_dates):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# get all the data from the csv file where the dates are in the reference_dates list\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(df[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m     date_series = df[\u001b[33m\"\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nimas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nimas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:300\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    297\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    299\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nimas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1645\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1642\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1644\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nimas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1904\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1902\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1903\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1904\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1913\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1914\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1915\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nimas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:926\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    921\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    922\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    923\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    934\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    935\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls'"
     ]
    }
   ],
   "source": [
    "dataFrame_H5A4 = getPricesFromCSV(\"C:/Users/nimas/Regentfund Repository/fixed-income/Data Files/H5A4.csv\", \"/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\")\n",
    "dataFrame_SPY = getPricesFromCSV(\"/fixed-income/Data Files/SPY 1.csv\", \"/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\")\n",
    "dataFrame_G5O2 = getPricesFromCSV(\"/fixed-income/Data Files/G5O2.csv\", \"/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\")\n",
    "dataFrame_TLT = getPricesFromCSV(\"/fixed-income/Data Files/TLT_simplified.csv\", \"/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\")\n",
    "dataFrame_LQD = getPricesFromCSV(\"/fixed-income/Data Files/LQD_simplified.csv\", \"/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\")\n",
    "dataFrame_C5A0 = getPricesFromCSV(\"/fixed-income/Data Files/C5A0.csv\", \"/Volumes/Raghav_DATA/Capitalfund/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7455278",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataFrame_H5A4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     21\u001b[39m     dates = bmom.index\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bmom, momentums, dates, daily_returns\n\u001b[32m     25\u001b[39m bmom_H5A4, momentums_H5A4, dates_H5A4, daily_returns_H5A4 = create_bmom(\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43mdataFrame_H5A4\u001b[49m,\n\u001b[32m     27\u001b[39m     {\u001b[32m20\u001b[39m: \u001b[32m0.15\u001b[39m, \u001b[32m60\u001b[39m: \u001b[32m0.35\u001b[39m, \u001b[32m120\u001b[39m: \u001b[32m0.35\u001b[39m, \u001b[32m240\u001b[39m: \u001b[32m0.15\u001b[39m},\n\u001b[32m     28\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mH5A4\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m )\n\u001b[32m     31\u001b[39m bmom_SPY, momentums_SPY, dates_SPY, daily_returns_SPY = create_bmom(\n\u001b[32m     32\u001b[39m     dataFrame_SPY,\n\u001b[32m     33\u001b[39m     {\u001b[32m20\u001b[39m: \u001b[32m0.15\u001b[39m, \u001b[32m60\u001b[39m: \u001b[32m0.35\u001b[39m, \u001b[32m120\u001b[39m: \u001b[32m0.35\u001b[39m, \u001b[32m240\u001b[39m: \u001b[32m0.15\u001b[39m},\n\u001b[32m     34\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSPY_adj_close\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m )\n\u001b[32m     37\u001b[39m bmom_G5O2, momentums_G5O2, dates_G5O2, daily_returns_G5O2 = create_bmom(\n\u001b[32m     38\u001b[39m     dataFrame_G5O2,\n\u001b[32m     39\u001b[39m     {\u001b[32m20\u001b[39m: \u001b[32m0.15\u001b[39m, \u001b[32m60\u001b[39m: \u001b[32m0.35\u001b[39m, \u001b[32m120\u001b[39m: \u001b[32m0.35\u001b[39m, \u001b[32m240\u001b[39m: \u001b[32m0.15\u001b[39m},\n\u001b[32m     40\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mG5O2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     41\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'dataFrame_H5A4' is not defined"
     ]
    }
   ],
   "source": [
    "def create_bmom(dataframe, weights, price_col=\"Price\"):\n",
    "    data = dataframe.dropna().sort_values(\"Date\").set_index(\"Date\")\n",
    "\n",
    "    px = data[price_col]\n",
    "    momentums = {}\n",
    "    weighted_momentums = {}\n",
    "\n",
    "    for lookback, weight in weights.items():\n",
    "        momentums[lookback] = px.pct_change(lookback)\n",
    "        weighted_momentums[lookback] = momentums[lookback] * weight\n",
    "\n",
    "    wm_df = pd.concat(weighted_momentums, axis=1)\n",
    "\n",
    "    # Find first index where ALL lookbacks are valid\n",
    "    first_valid = wm_df.dropna().index[0]\n",
    "\n",
    "    # Sum only from that index onward\n",
    "    bmom = wm_df.loc[first_valid:].sum(axis=1)\n",
    "\n",
    "    daily_returns = px.pct_change(1)\n",
    "    dates = bmom.index\n",
    "\n",
    "    return bmom, momentums, dates, daily_returns\n",
    "\n",
    "bmom_H5A4, momentums_H5A4, dates_H5A4, daily_returns_H5A4 = create_bmom(\n",
    "    dataFrame_H5A4,\n",
    "    {20: 0.15, 60: 0.35, 120: 0.35, 240: 0.15},\n",
    "    \"H5A4\"\n",
    ")\n",
    "\n",
    "bmom_SPY, momentums_SPY, dates_SPY, daily_returns_SPY = create_bmom(\n",
    "    dataFrame_SPY,\n",
    "    {20: 0.15, 60: 0.35, 120: 0.35, 240: 0.15},\n",
    "    \"SPY_adj_close\"\n",
    ")\n",
    "\n",
    "bmom_G5O2, momentums_G5O2, dates_G5O2, daily_returns_G5O2 = create_bmom(\n",
    "    dataFrame_G5O2,\n",
    "    {20: 0.15, 60: 0.35, 120: 0.35, 240: 0.15},\n",
    "    \"G5O2\"\n",
    ")\n",
    "\n",
    "\n",
    "bmom_TLT, momentums_TLT, dates_TLT, daily_returns_TLT = create_bmom(\n",
    "    dataFrame_TLT,\n",
    "    {20: 0.15, 60: 0.35, 120: 0.35, 240: 0.15},\n",
    "    \"TLT\"\n",
    ")\n",
    "bmom_LQD, momentums_LQD, dates_LQD, daily_returns_LQD = create_bmom(\n",
    "    dataFrame_LQD,\n",
    "    {20: 0.15, 60: 0.35, 120: 0.35, 240: 0.15},\n",
    "    \"LQD\"\n",
    ")\n",
    "bmom_C5A0, momentums_C5A0, dates_C5A0, daily_returns_C5A0 = create_bmom(\n",
    "    dataFrame_C5A0,\n",
    "    {20: 0.15, 60: 0.35, 120: 0.35, 240: 0.15},\n",
    "    \"C5A0\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47775de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat1_signals(bmom_asset, bmom_benchmark, mom240_asset, thresh=-0.03, init_wgt=0):\n",
    "    # Use asset index as the master timeline (like the sheet's Date column)\n",
    "    idx = bmom_asset.index\n",
    "    a = bmom_asset.astype(float)\n",
    "    s = bmom_benchmark.reindex(idx).astype(float)\n",
    "    m240 = mom240_asset.reindex(idx).astype(float)\n",
    "\n",
    "    # Cross-down conditions (NaNs will naturally evaluate to False in comparisons)\n",
    "    cond1 = (s.shift(1) > thresh) & (s < thresh) & (a < thresh)\n",
    "    cond2 = (a.shift(1) > thresh) & (a < thresh) & (s < thresh)\n",
    "\n",
    "    risk_off = (cond1 | cond2) & (m240 < 0)\n",
    "\n",
    "    # Desired signal: 0 on risk_off, 1 if a>0, else NaN (to be forward-filled)\n",
    "    sig = pd.Series(np.nan, index=idx, dtype=\"float64\")\n",
    "    sig = sig.mask(risk_off, 0)\n",
    "    sig = sig.mask(~risk_off & (a > 0), 1)\n",
    "\n",
    "    # Spreadsheet-style initialization + carry forward\n",
    "    sig.iloc[0] = init_wgt\n",
    "    sig = sig.ffill().astype(int)\n",
    "\n",
    "    #make sure to align with smaller of the two date ranges between asset and benchmark\n",
    "    min_idx = idx.intersection(bmom_benchmark.index)\n",
    "    sig = sig.reindex(min_idx)\n",
    "\n",
    "    return sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd8dc20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bmom_H5A4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m signals_strat1_H5A4 = strat1_signals(\u001b[43mbmom_H5A4\u001b[49m, bmom_SPY, momentums_H5A4[\u001b[32m240\u001b[39m], thresh=-\u001b[32m0.03\u001b[39m)\n\u001b[32m      2\u001b[39m signals_strat1_G5O2 = strat1_signals(bmom_G5O2, bmom_TLT, momentums_G5O2[\u001b[32m240\u001b[39m], thresh=-\u001b[32m0.03\u001b[39m)\n\u001b[32m      3\u001b[39m signals_strat1_C5A0 = strat1_signals(bmom_C5A0, bmom_LQD, momentums_C5A0[\u001b[32m240\u001b[39m], thresh=-\u001b[32m0.03\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'bmom_H5A4' is not defined"
     ]
    }
   ],
   "source": [
    "signals_strat1_H5A4 = strat1_signals(bmom_H5A4, bmom_SPY, momentums_H5A4[240], thresh=-0.03)\n",
    "signals_strat1_G5O2 = strat1_signals(bmom_G5O2, bmom_TLT, momentums_G5O2[240], thresh=-0.03)\n",
    "signals_strat1_C5A0 = strat1_signals(bmom_C5A0, bmom_LQD, momentums_C5A0[240], thresh=-0.03)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58480622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat2_from_strat1(strat1: pd.Series,\n",
    "                       hyg_ret: pd.Series,\n",
    "                       drawdiffthresh: float = 0.10) -> pd.Series:\n",
    "    idx = strat1.index\n",
    "    r_hyg = hyg_ret.reindex(idx).fillna(0.0)\n",
    "\n",
    "    # Strat1 returns use previous-day weight (typical backtest convention)\n",
    "    r_strat1 = r_hyg * strat1.shift(1).fillna(0)\n",
    "\n",
    "    def drawdown(r: pd.Series) -> pd.Series:\n",
    "        eq = (1.0 + r).cumprod()\n",
    "        return eq / eq.cummax() - 1\n",
    "\n",
    "    dd_strat1 = drawdown(r_strat1)\n",
    "    dd_hyg = drawdown(r_hyg)\n",
    "\n",
    "\n",
    "    dd_diff = dd_strat1 - dd_hyg\n",
    "\n",
    "\n",
    "    override_trigger = dd_diff > drawdiffthresh\n",
    "    \n",
    "    # Identify start of each override regime\n",
    "    override_start = override_trigger & (~override_trigger.shift(1, fill_value=False))\n",
    "    \n",
    "    # Each override regime gets a unique ID\n",
    "    regime_id = override_start.cumsum()\n",
    "    \n",
    "    # Determine where an override regime should end:\n",
    "    # first date AFTER regime start where strat1 == 1\n",
    "    end_override = (regime_id > 0) & (strat1 == 1)\n",
    "    \n",
    "    # For each regime, find first exit index\n",
    "    first_exit = (\n",
    "        end_override.groupby(regime_id)\n",
    "        .transform(lambda x: x & (~x.shift(1, fill_value=False)))\n",
    "    )\n",
    "    \n",
    "    # Build active override mask\n",
    "    active_override = (\n",
    "        (regime_id > 0)\n",
    "        & ~(first_exit.groupby(regime_id).cumsum().astype(bool))\n",
    "    )\n",
    "    \n",
    "    # Strat2 logic\n",
    "    strat2 = strat1.copy()\n",
    "    strat2[active_override] = 1\n",
    "    strat2[override_trigger] = 1   # threshold always wins\n",
    "    \n",
    "    strat2.iloc[0] = 0\n",
    "    \n",
    "    return strat2\n",
    "\n",
    "\n",
    "\n",
    "strat2_signals_H5A4 = (strat2_from_strat1(signals_strat1_H5A4, daily_returns_H5A4, drawdiffthresh=0.10))\n",
    "strat2_signals_G5O2 = (strat2_from_strat1(signals_strat1_G5O2, daily_returns_G5O2, drawdiffthresh=0.10))\n",
    "strat2_signals_C5A0 = (strat2_from_strat1(signals_strat1_C5A0, daily_returns_C5A0, drawdiffthresh=0.10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: /Volumes/Raghav_DATA/Capitalfund/fixed-income/strat2_output.csv\n",
      "Annualized Return: 0.012\n",
      "Annualized Volatility: 0.044\n",
      "Sharpe Ratio: 0.28\n",
      "file: /Volumes/Raghav_DATA/Capitalfund/fixed-income/strat1_output.csv\n",
      "Annualized Return: 0.0087\n",
      "Annualized Volatility: 0.036\n",
      "Sharpe Ratio: 0.24\n"
     ]
    }
   ],
   "source": [
    "def analyze_strat(signals: pd.Series, daily_returns: pd.Series, file_path):\n",
    "    idx = signals.index\n",
    "    r_strat = daily_returns.reindex(idx).fillna(0.0) * signals.shift(1).fillna(0)\n",
    "    \n",
    "    def drawdown(r: pd.Series) -> pd.Series:\n",
    "        eq = (1.0 + r).cumprod()\n",
    "        return eq / eq.cummax() - 1\n",
    "\n",
    "    def equity_curve(r: pd.Series) -> pd.Series:\n",
    "        return (1.0 + r).cumprod()\n",
    "    \n",
    "    def annualized_return(r: pd.Series) -> float:\n",
    "        equity = equity_curve(r)\n",
    "        return equity.iloc[-1] ** (252 / len(r)) - 1  # Annualized return\n",
    "    def volatility(r: pd.Series) -> float:\n",
    "        return r.std() * np.sqrt(252)  # Annualized volatility\n",
    "    def sharpe_ratio(r: pd.Series, risk_free_rate=0.0) -> float:\n",
    "        ann_return = annualized_return(r)\n",
    "        ann_vol = volatility(r)\n",
    "        return ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "    print(\"file:\", file_path)\n",
    "    print(f\"Annualized Return: {annualized_return(r_strat):.2}\")\n",
    "    print(f\"Annualized Volatility: {volatility(r_strat):.2}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio(r_strat):.2}\")\n",
    "    \n",
    "    #Write to CSV\n",
    "    output_df = pd.DataFrame({\n",
    "        \"Date\": idx,\n",
    "        \"Signal\": signals,\n",
    "        \"Daily Return\": r_strat,\n",
    "        \"Drawdown\": drawdown(r_strat),\n",
    "        \"Equity Curve\": equity_curve(r_strat)\n",
    "    })\n",
    "    output_df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "analyze_strat(strat2_signals_H5A4, daily_returns_H5A4, \"/Volumes/Raghav_DATA/Capitalfund/fixed-income/strat2_output.csv\")\n",
    "analyze_strat(signals_strat1_H5A4, daily_returns_H5A4, \"/Volumes/Raghav_DATA/Capitalfund/fixed-income/strat1_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6644145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2008-03-25    0\n",
      "2008-03-26    1\n",
      "2008-03-27    1\n",
      "2008-03-28    1\n",
      "2008-03-31    1\n",
      "             ..\n",
      "2025-11-05    1\n",
      "2025-11-06    1\n",
      "2025-11-07    1\n",
      "2025-11-10    1\n",
      "2025-11-11    1\n",
      "Length: 4439, dtype: int64\n",
      "Date\n",
      "2008-03-25    0\n",
      "2008-03-26    1\n",
      "2008-03-27    1\n",
      "2008-03-28    1\n",
      "2008-03-31    1\n",
      "             ..\n",
      "2025-11-05    1\n",
      "2025-11-06    1\n",
      "2025-11-07    1\n",
      "2025-11-10    1\n",
      "2025-11-11    1\n",
      "Length: 4439, dtype: int64\n",
      "Date\n",
      "1997-12-11    0\n",
      "1997-12-12    1\n",
      "1997-12-15    1\n",
      "1997-12-16    1\n",
      "1997-12-17    1\n",
      "             ..\n",
      "2025-11-05    1\n",
      "2025-11-06    1\n",
      "2025-11-07    1\n",
      "2025-11-10    1\n",
      "2025-11-11    1\n",
      "Length: 7023, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(strat2_signals_G5O2)\n",
    "print(strat2_signals_C5A0)\n",
    "print(strat2_signals_H5A4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d4f8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "471d3000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Cash      H5A4      C5A0      G5O2\n",
      "Date                                          \n",
      "1997-12-11  0.10  0.000000  0.000000  0.900000\n",
      "1997-12-12  0.05  0.950000  0.000000  0.000000\n",
      "1997-12-15  0.05  0.950000  0.000000  0.000000\n",
      "1997-12-16  0.05  0.950000  0.000000  0.000000\n",
      "1997-12-17  0.05  0.950000  0.000000  0.000000\n",
      "...          ...       ...       ...       ...\n",
      "2025-11-05  0.05  0.267542  0.361847  0.320610\n",
      "2025-11-06  0.05  0.224967  0.375060  0.349973\n",
      "2025-11-07  0.05  0.232338  0.362998  0.354664\n",
      "2025-11-10  0.05  0.280022  0.341943  0.328036\n",
      "2025-11-11  0.05  0.285006  0.342490  0.322504\n",
      "\n",
      "[7023 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def strat_3(bmom, signals, daily_returns):\n",
    "\n",
    "    assets = [\"H5A4\", \"C5A0\", \"G5O2\"]\n",
    "\n",
    "    # Use index from one of the series\n",
    "    idx = bmom[assets[0]].index\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1. Linear momentum scores\n",
    "    # -----------------------------\n",
    "    scores = pd.DataFrame(index=idx, columns=assets, dtype=float)\n",
    "\n",
    "    for asset in assets:\n",
    "        excess_bmom = np.maximum(0.0, bmom[asset].reindex(idx))\n",
    "        scores[asset] = excess_bmom * signals[asset].reindex(idx)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2. Weight calculation\n",
    "    # -----------------------------\n",
    "    weights = pd.DataFrame(index=idx,\n",
    "                           columns=[\"Cash\"] + assets,\n",
    "                           dtype=float)\n",
    "\n",
    "    for i in range(len(scores)):\n",
    "        row_scores = scores.iloc[i]\n",
    "        total = row_scores.sum()\n",
    "\n",
    "        # Defensive mode\n",
    "        if total == 0:\n",
    "            weights.iloc[i] = [0.10, 0.0, 0.0, 0.90]\n",
    "            continue\n",
    "\n",
    "        # Active mode\n",
    "        cash = 0.05\n",
    "        raw = (row_scores / total) * 0.95\n",
    "\n",
    "        active_assets = raw[raw > 0].index.tolist()\n",
    "\n",
    "        # Enforce 5% minimum\n",
    "        for a in active_assets:\n",
    "            if raw[a] < 0.05:\n",
    "                deficit = 0.05 - raw[a]\n",
    "                raw[a] = 0.05\n",
    "\n",
    "                others = [x for x in active_assets if x != a]\n",
    "                if len(others) > 0:\n",
    "                    other_total = raw[others].sum()\n",
    "                    for o in others:\n",
    "                        raw[o] -= deficit * (raw[o] / other_total)\n",
    "\n",
    "        weights.iloc[i] = [cash,\n",
    "                           raw[\"H5A4\"],\n",
    "                           raw[\"C5A0\"],\n",
    "                           raw[\"G5O2\"]]\n",
    "        \n",
    "    # -----------------------------\n",
    "    # 3. Portfolio returns\n",
    "    # -----------------------------\n",
    "    portfolio_return = (\n",
    "        weights[\"H5A4\"].shift(1) * daily_returns[\"H5A4\"].reindex(idx) +\n",
    "        weights[\"C5A0\"].shift(1) * daily_returns[\"C5A0\"].reindex(idx) +\n",
    "        weights[\"G5O2\"].shift(1) * daily_returns[\"G5O2\"].reindex(idx)\n",
    "    ).fillna(0.0)\n",
    "\n",
    "    equity_curve = (1 + portfolio_return).cumprod()\n",
    "    weights = weights.fillna(0.0)\n",
    "\n",
    "    return weights, portfolio_return, equity_curve, scores\n",
    "weights3, ret3, eq3, scores3 = strat_3(\n",
    "    bmom={\n",
    "        \"H5A4\": bmom_H5A4,\n",
    "        \"C5A0\": bmom_C5A0,\n",
    "        \"G5O2\": bmom_G5O2\n",
    "    },\n",
    "    signals={\n",
    "        \"H5A4\": strat2_signals_H5A4,\n",
    "        \"C5A0\": strat2_signals_C5A0,\n",
    "        \"G5O2\": strat2_signals_G5O2\n",
    "    },\n",
    "    daily_returns={\n",
    "        \"H5A4\": daily_returns_H5A4,\n",
    "        \"C5A0\": daily_returns_C5A0,\n",
    "        \"G5O2\": daily_returns_G5O2\n",
    "    }\n",
    ")\n",
    "\n",
    "print(weights3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
