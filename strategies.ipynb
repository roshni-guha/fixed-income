{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860ab9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1721add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPricesFromCSV(file_path, reference_dates):\n",
    "    # get all the data from the csv file where the dates are in the reference_dates list\n",
    "    df = pd.read_csv(reference_dates, skiprows=15)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "    date_series = df[\"Date\"]\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%Y%m%d\")\n",
    "    df_filtered = df[df[\"Date\"].isin(date_series)]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "118f6cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame_H5A4 = getPricesFromCSV(\"/Volumes/Raghav_DATA/Capitalfund/fixed-income/Data Files/H5A4.csv\", \"/Volumes/Raghav_DATA/Capitalfund/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\")\n",
    "dataFrame_SPY = getPricesFromCSV(\"/Volumes/Raghav_DATA/Capitalfund/fixed-income/Data Files/SPY 1.csv\", \"/Volumes/Raghav_DATA/Capitalfund/fixed-income/Data Files/MLH5A4_Price_History(Fixed Income).xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7455278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bmom(dataframe, weights, price_col=\"Price\"):\n",
    "    data = dataframe.dropna().sort_values(\"Date\").set_index(\"Date\")\n",
    "\n",
    "    px = data[price_col]\n",
    "    momentums = {}\n",
    "    weighted_momentums = {}\n",
    "\n",
    "    for lookback, weight in weights.items():\n",
    "        momentums[lookback] = px.pct_change(lookback)\n",
    "        weighted_momentums[lookback] = momentums[lookback] * weight\n",
    "\n",
    "    wm_df = pd.concat(weighted_momentums, axis=1)\n",
    "\n",
    "    # Find first index where ALL lookbacks are valid\n",
    "    first_valid = wm_df.dropna().index[0]\n",
    "\n",
    "    # Sum only from that index onward\n",
    "    bmom = wm_df.loc[first_valid:].sum(axis=1)\n",
    "\n",
    "    daily_returns = px.pct_change(1)\n",
    "    dates = bmom.index\n",
    "\n",
    "    return bmom, momentums, dates, daily_returns\n",
    "\n",
    "bmom_H5A4, momentums_H5A4, dates_H5A4, daily_returns_H5A4 = create_bmom(\n",
    "    dataFrame_H5A4,\n",
    "    {20: 0.15, 60: 0.35, 120: 0.35, 240: 0.15},\n",
    "    \"H5A4\"\n",
    ")\n",
    "\n",
    "bmom_SPY, momentums_SPY, dates_SPY, daily_returns_SPY = create_bmom(\n",
    "    dataFrame_SPY,\n",
    "    {20: 0.15, 60: 0.35, 120: 0.35, 240: 0.15},\n",
    "    \"SPY_adj_close\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47775de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat1_signals(bmom_asset, bmom_spy, mom240_asset, thresh=-0.03, init_wgt=0):\n",
    "    # Use asset index as the master timeline (like the sheet's Date column)\n",
    "    idx = bmom_asset.index\n",
    "    a = bmom_asset.astype(float)\n",
    "    s = bmom_spy.reindex(idx).astype(float)\n",
    "    m240 = mom240_asset.reindex(idx).astype(float)\n",
    "\n",
    "    # Cross-down conditions (NaNs will naturally evaluate to False in comparisons)\n",
    "    cond1 = (s.shift(1) > thresh) & (s < thresh) & (a < thresh)\n",
    "    cond2 = (a.shift(1) > thresh) & (a < thresh) & (s < thresh)\n",
    "\n",
    "    risk_off = (cond1 | cond2) & (m240 < 0)\n",
    "\n",
    "    # Desired signal: 0 on risk_off, 1 if a>0, else NaN (to be forward-filled)\n",
    "    sig = pd.Series(np.nan, index=idx, dtype=\"float64\")\n",
    "    sig = sig.mask(risk_off, 0)\n",
    "    sig = sig.mask(~risk_off & (a > 0), 1)\n",
    "\n",
    "    # Spreadsheet-style initialization + carry forward\n",
    "    sig.iloc[0] = init_wgt\n",
    "    sig = sig.ffill().astype(int)\n",
    "\n",
    "    return sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afd8dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_strat1 = strat1_signals(bmom_H5A4, bmom_SPY, momentums_H5A4[240], thresh=-0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58480622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strat2_from_strat1(strat1: pd.Series,\n",
    "                       hyg_ret: pd.Series,\n",
    "                       drawdiffthresh: float = 0.10) -> pd.Series:\n",
    "    idx = strat1.index\n",
    "    r_hyg = hyg_ret.reindex(idx).fillna(0.0)\n",
    "\n",
    "    # Strat1 returns use previous-day weight (typical backtest convention)\n",
    "    r_strat1 = r_hyg * strat1.shift(1).fillna(0)\n",
    "\n",
    "    def drawdown(r: pd.Series) -> pd.Series:\n",
    "        eq = (1.0 + r).cumprod()\n",
    "        return eq / eq.cummax() - 1\n",
    "\n",
    "    dd_strat1 = drawdown(r_strat1)\n",
    "    dd_hyg = drawdown(r_hyg)\n",
    "\n",
    "\n",
    "    dd_diff = dd_strat1 - dd_hyg\n",
    "\n",
    "\n",
    "    override_trigger = dd_diff > drawdiffthresh\n",
    "    \n",
    "    # Identify start of each override regime\n",
    "    override_start = override_trigger & (~override_trigger.shift(1, fill_value=False))\n",
    "    \n",
    "    # Each override regime gets a unique ID\n",
    "    regime_id = override_start.cumsum()\n",
    "    \n",
    "    # Determine where an override regime should end:\n",
    "    # first date AFTER regime start where strat1 == 1\n",
    "    end_override = (regime_id > 0) & (strat1 == 1)\n",
    "    \n",
    "    # For each regime, find first exit index\n",
    "    first_exit = (\n",
    "        end_override.groupby(regime_id)\n",
    "        .transform(lambda x: x & (~x.shift(1, fill_value=False)))\n",
    "    )\n",
    "    \n",
    "    # Build active override mask\n",
    "    active_override = (\n",
    "        (regime_id > 0)\n",
    "        & ~(first_exit.groupby(regime_id).cumsum().astype(bool))\n",
    "    )\n",
    "    \n",
    "    # Strat2 logic\n",
    "    strat2 = strat1.copy()\n",
    "    strat2[active_override] = 1\n",
    "    strat2[override_trigger] = 1   # threshold always wins\n",
    "    \n",
    "    strat2.iloc[0] = 0\n",
    "    \n",
    "    return strat2\n",
    "\n",
    "\n",
    "\n",
    "strat2_signals = (strat2_from_strat1(signals_strat1, daily_returns_H5A4, drawdiffthresh=0.10))\n",
    "strat2_zero = strat2_signals[strat2_signals == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c81453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: /Volumes/Raghav_DATA/Capitalfund/fixed-income/strat2_output.csv\n",
      "Annualized Return: 0.012\n",
      "Annualized Volatility: 0.044\n",
      "Sharpe Ratio: 0.28\n",
      "file: /Volumes/Raghav_DATA/Capitalfund/fixed-income/strat1_output.csv\n",
      "Annualized Return: 0.0087\n",
      "Annualized Volatility: 0.036\n",
      "Sharpe Ratio: 0.24\n"
     ]
    }
   ],
   "source": [
    "def analyze_strat(signals: pd.Series, daily_returns: pd.Series, file_path):\n",
    "    idx = signals.index\n",
    "    r_strat = daily_returns.reindex(idx).fillna(0.0) * signals.shift(1).fillna(0)\n",
    "    \n",
    "    def drawdown(r: pd.Series) -> pd.Series:\n",
    "        eq = (1.0 + r).cumprod()\n",
    "        return eq / eq.cummax() - 1\n",
    "\n",
    "    def equity_curve(r: pd.Series) -> pd.Series:\n",
    "        return (1.0 + r).cumprod()\n",
    "    \n",
    "    def annualized_return(r: pd.Series) -> float:\n",
    "        equity = equity_curve(r)\n",
    "        return equity.iloc[-1] ** (252 / len(r)) - 1  # Annualized return\n",
    "    def volatility(r: pd.Series) -> float:\n",
    "        return r.std() * np.sqrt(252)  # Annualized volatility\n",
    "    def sharpe_ratio(r: pd.Series, risk_free_rate=0.0) -> float:\n",
    "        ann_return = annualized_return(r)\n",
    "        ann_vol = volatility(r)\n",
    "        return ann_return / ann_vol if ann_vol > 0 else np.nan\n",
    "    print(\"file:\", file_path)\n",
    "    print(f\"Annualized Return: {annualized_return(r_strat):.2}\")\n",
    "    print(f\"Annualized Volatility: {volatility(r_strat):.2}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio(r_strat):.2}\")\n",
    "    \n",
    "    #Write to CSV\n",
    "    output_df = pd.DataFrame({\n",
    "        \"Date\": idx,\n",
    "        \"Signal\": signals,\n",
    "        \"Daily Return\": r_strat,\n",
    "        \"Drawdown\": drawdown(r_strat),\n",
    "        \"Equity Curve\": equity_curve(r_strat)\n",
    "    })\n",
    "    output_df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "analyze_strat(strat2_signals, daily_returns_H5A4, \"/Volumes/Raghav_DATA/Capitalfund/fixed-income/strat2_output.csv\")\n",
    "analyze_strat(signals_strat1, daily_returns_H5A4, \"/Volumes/Raghav_DATA/Capitalfund/fixed-income/strat1_output.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
